# -*- coding: utf-8 -*-
"""Bike_Sharing_Demand_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cr5cD6TbiWSxMXknA7zVySkSEo__Cbhc

#**Importing Required Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly.express as px
from scipy.stats import norm
import pandas as pd
import numpy as np
import tensorflow as tf
from datetime import datetime
import calendar
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.preprocessing import  LabelEncoder
from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet
from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn import neighbors
from lightgbm import LGBMRegressor
import lightgbm
from xgboost import XGBRegressor
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn import metrics
from sklearn.metrics import r2_score as r2
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import mean_absolute_error
pd.options.display.max_rows = 50
pd.options.display.float_format = "{:.3f}".format
import warnings
warnings.filterwarnings('ignore')

"""# **Loading Data**

"""

b_data = pd.read_csv("data.csv", encoding ="ISO-8859-1")

"""#**Studying Data**"""

b_data.head()

b_data.shape

b_data.describe().T

b_data.rename({"Temperature(°C)": "Temperature",
               "Functioning Day":"Functioning_Day",
                "Humidity(%)": "Humidity",
                "Wind speed (m/s)": "Wind_speed",
                "Visibility (10m)": "Visibility",
                "Dew point temperature(°C)": "Dew_point_temperature",
                "Solar Radiation (MJ/m2)": "Solar_Radiation",
                "Snowfall (cm)": "Snowfall",
                "Rainfall(mm)": "Rainfall",
                "Rented Bike Count": "Rented_Bike_Count"},
                axis = "columns", inplace = True)

b_data.isnull().sum()

b_data.duplicated().value_counts()

df = b_data.copy()
df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True, dayfirst=True)
df['month'] = pd.DatetimeIndex(df['Date']).month
df['month'] = df['month'].apply(lambda x: calendar.month_abbr[x])
df['day'] = df['Date'].dt.day_name()
df['year'] = df['Date'].dt.year
df.head(1)

def total(df,var):
  total = len(df[var].value_counts())
  return total

total_lenght_different_column = {
    'Seasons': total(df,'Seasons'),
    'Holiday': total(df,'Holiday'),
    'Funtioning_Day': total(df,'Functioning_Day'),
    'month' : total(df,'month'),
    'day'   : total(df,'day'),
    'year'  : total(df,'year')
}

total_df = pd.DataFrame.from_dict(total_lenght_different_column,orient='index')
total_df.T

df.drop(columns=['Date'],inplace=True)

df['Hour']=df['Hour'].astype('object')
df['year'] = df['year'].astype('object')

df.info()

"""# **Exploratory Data Analysis**

"""

num_feature = df.select_dtypes(exclude='object')
print(f'Numerical feature : {num_feature.columns.to_list()}')

cat_feature = df.select_dtypes(include='object')
print(f'Categorical feature : {cat_feature.columns.to_list()}')

def density_plot(df,num_feature):
  graph = plt.figure(figsize = (20,30))
  for i,col in enumerate(num_feature) :
    plt.subplot(6,2,i+1);
    sns.distplot(df[col], color = '#055E85');
    feature = df[col]
    plt.axvline(feature.mean(), color='#ff033e', linestyle='dashed', linewidth=3,label= 'mean');
    plt.axvline(feature.median(), color='#A020F0', linestyle='dashed', linewidth=3,label='median');
    plt.tight_layout();

density_plot(df,num_feature)

for i in df.columns:
  plt.figure(figsize=(15,6))
  if i == 'Rented_Bike_Count':
    pass
  elif i in ['Seasons','Holiday','Functioning_Day','month','year']:
    grp = df.groupby([i], as_index = False)['Rented_Bike_Count'].sum().sort_values('Rented_Bike_Count', ascending = False)
    sns.barplot(x=grp[i], y=grp["Rented_Bike_Count"]);
    plt.title(f"Rented_Bike_Count for {i} ");
    print('\n')
  elif i == 'day':
    workingdays = {'day':['Monday','Tuesday','Wednesday','Thursday','Friday',	'Saturday',	'Sunday']}
    workingday = pd.DataFrame(workingdays)
    grp = df.groupby([i], as_index = False)['Rented_Bike_Count'].sum().sort_values('Rented_Bike_Count',ascending = False)
    chart = workingday.merge(grp)
    sns.lineplot(data= chart, x=chart[i],y= chart['Rented_Bike_Count'], marker= 'o', color = 'blue');
    plt.xticks(fontsize = 14, rotation = 90);
    plt.title(f"Rented_Bike_Count for {i} ");
  else :
    grp = df.groupby([i], as_index = False)['Rented_Bike_Count'].sum().sort_values('Rented_Bike_Count', ascending = False).head(20)
    sns.set_context('notebook');
    sns.pointplot(x=grp[i], y=grp["Rented_Bike_Count"]);
    plt.title(f"Rented_Bike_Count for {i} ");
    print('\n')

  plt.show()

def group_by(df,feature):
  data = df.groupby([feature], as_index = False)['Rented_Bike_Count'].sum().sort_values('Rented_Bike_Count', ascending = False)
  return data

group_by(df,'Functioning_Day')

group_by(df,'Holiday')

group_by(df,'year')

group_by(df,'Seasons')

weekend = group_by(df,'day')
chutti = weekend[(weekend['day'] == 'Saturday') | (weekend['day'] == 'Sunday')]
chutti

workingday = group_by(df,'day')
office = workingday[(workingday['day'] != 'Saturday') & (workingday['day'] != 'Sunday')]
office

"""# **Encoding Categorial Variable**"""

df = df.drop(['Functioning_Day','day','year','Dew_point_temperature'], axis = 1)
df.shape

num = df.select_dtypes(exclude ='object')
cat = df.select_dtypes(include ='object')
print(f' numeric: {num.columns.to_list()}\n categorial : {cat.columns.to_list()}')

encoded = df.apply(LabelEncoder().fit_transform)
encoded.head(1)

"""#**Model Training**"""

X=encoded.drop('Rented_Bike_Count',axis=1)
y=encoded['Rented_Bike_Count']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 7)

print(f'Shape of X_train => {X_train.shape}, Shape of X_test => {X_test.shape}' )
print(f'Shape of y_train => {y_train.shape}, Shape of y_test => {y_test.shape}' )

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
y_train = scaler.fit_transform(y_train.values.reshape(-1, 1))
y_test = scaler.transform(y_test.values.reshape(-1, 1))

model1 = [
          ['Linear Regression ', LinearRegression()],
           ['Lasso ', Lasso(alpha =0.1 , max_iter= 2000)],
           ['Ridge ', Ridge(alpha =0.1 , max_iter= 2000)],
           ['KNeighborsRegressor ',  neighbors.KNeighborsRegressor()],
           ['RandomForest ',RandomForestRegressor(criterion='absolute_error',random_state=42)]
        ]

model_score = []
for name, model in model1:
    model_data = {}
    model_data["Name"] = name
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    model_data["MSE"] = mse(y_test, y_pred)
    model_data["RMSE"] = np.sqrt(model_data["MSE"])
    model_data["R2_Score"] = r2(y_test, y_pred)
    model_data["ADJ_R2"] = 1 - (1 - r2(y_test, y_pred)) * ((X_test.shape[0] - 1) / (X_test.shape[0] - X_test.shape[1] - 1))
    print(f'    {20 * "="}  {name} {20 * "="}')
    model_score.append(model_data)

model1_df = pd.DataFrame(model_score)
model1_df